# -*- coding: utf-8 -*-
"""Linear Regression BOOTCAMP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hHUYmGkjB6uyB7sAz_JB86dnZJAwOj2H
"""

import numpy as np
import matplotlib.pyplot as plt

X = np.array([1,2,3,4,5])
y = np.array([35,50,65,80,95])

w = 0.0
b = 0.0

def predict(X, w, b):
  return w * X + b

def compute_cost(X, y, w, b):
  n = len(X)

  prediction = predict(X,w,b)
  error = prediction - y
  cost = (1/n)*np.sum(error**2)
  return cost

def gradient_descent(X, y, w, b, learning_rate, iterations):
  n = len(X)

  cost_history = []
  iteration_history = []

  for i in range(iterations):
    predictions = predict(X,w,b)
    error = predictions - y

    dw = (2/n)*np.sum(error*X)
    db = (2/n)*np.sum(error)

    w = w - learning_rate * dw
    b = b - learning_rate * db

    if i%50 == 0:
      cost = compute_cost(X,y,w,b)
      cost_history.append(cost)
      iteration_history.append(i)
      print(f"Iteration {i}, cost: {cost}")
  return w,b, cost_history, iteration_history

learning_rate = 0.01
iterations = 500

w, b, cost_history, iteration_history = gradient_descent(X,y,w,b,learning_rate, iterations )
print("Final weight :", w)
print("Final bias :", b)

plt.plot(iteration_history, cost_history)
plt.xlabel("C.H")
plt.ylabel("I.H")
plt.title("cost vs iteration")
plt.show()

predictions = predict(X, w, b)
plt.scatter(X,y)
plt.plot(X, predictions, color = "red")
plt.xlabel("Study hours")
plt.ylabel("Marks")
plt.show()

new_hours = np.array((3.5,5))
m = len(new_hours)

for i in range(m):
  predicted_marks = predict(new_hours[i], w, b)
  print("Predicted Marks:", predicted_marks)